{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "COMP 472 - Mini Project 1 - Fall 2021\n",
    "Due October 18th, 2021\n",
    "Team Samurai: Adrien Kamran (40095393), Abdul Sirawan (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TASK 2**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**STEP 2 - Load the dataset in Python.**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas\n",
    "dataset = pandas.read_csv(\"drug200.csv\")\n",
    "# Print the first 5 rows (header incl.) to see if this works as intended\n",
    "print(dataset.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**STEP 3 - Plot the distribution of the instances in each class, then store the graphic in a file called \"drug-distribution.pdf\".**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# For each column in the dataset...\n",
    "for column in dataset:\n",
    "    # Create a histogram of the data in the column's rows\n",
    "    plt.hist(dataset[column])\n",
    "    plt.title = column\n",
    "    # Save the figure as 'column_name.png'\n",
    "    plt.savefig(fname=column)\n",
    "    # Clear the plot's figure window to make room for the next one\n",
    "    plt.clf()\n",
    "\n",
    "# Assemble the PDF in an image editor to make the collage, save as PDF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preliminary observations:\n",
    "- Age: largest group between 40 and 50 yrs, smallest between 50 and 55 yrs.\n",
    "- Sex: nearly even split.\n",
    "- BP: more high than low, more low than normal.\n",
    "- Cholesterol: more high than normal.\n",
    "- Na to K: largest group between 10 and 15, smallest between 38 and 38.\n",
    "- Drug: more drug Y than anything else, less drug C than anything else."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**STEP 4 - For the dataset, convert ordinal features to ordered numerical, and nominal features to unordered numerical.**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# Convert unordered nominal features\n",
    "dataset = pandas.get_dummies(dataset, columns=['Sex'], prefix=['Sex'])\n",
    "# Convert ordered nominal features to their numeric codes\n",
    "dataset['BP'] = dataset['BP'].apply(lambda x: ['LOW', 'NORMAL', 'HIGH'].index(x))\n",
    "dataset['Cholesterol'] = dataset['Cholesterol'].apply(lambda x: ['NORMAL', 'HIGH'].index(x))\n",
    "# Convert target classes to arbitrary numeric codes\n",
    "dataset['Drug'].replace(to_replace=['drugA', 'drugB', 'drugC', 'drugX', 'drugY'], value=[1, 2, 3, 4, 5], inplace=True)\n",
    "# Swap columns due to get_dummies placing new columns at the end of the dataframe\n",
    "cols = list(dataset.columns)\n",
    "a, b = cols.index('Sex_M'), cols.index('Drug')\n",
    "cols[a], cols[b] = cols[b], cols[a]\n",
    "dataset = dataset[cols]\n",
    "print(dataset.head(5))\n",
    "\n",
    "# Create ordered categories for ordinal features\n",
    "# bp_cat = CategoricalDtype(categories = ['LOW', 'NORMAL', 'HIGH'], ordered = True)\n",
    "# chol_cat = CategoricalDtype(categories = ['NORMAL', 'HIGH'], ordered = True)\n",
    "# Assign ordered categories to respective features\n",
    "# dataset['BP'] = dataset['BP'].astype(bp_cat)\n",
    "# dataset['Cholesterol'] = dataset['Cholesterol'].astype(chol_cat)\n",
    "# Find columns with category data type\n",
    "# cat_columns = dataset.select_dtypes(['category']).columns\n",
    "# dataset[cat_columns] = dataset[cat_columns].apply(lambda x: x.cat.codes)\n",
    "# drug_cat = CategoricalDtype(categories = ['drugA', 'drugB', 'drugC', 'drugX', 'drugY'], ordered = False)\n",
    "# dataset['Drug'] = dataset['Drug'].astype(drug_cat)\n",
    "# Create unordered categories for nominal features\n",
    "# sex_cat = CategoricalDtype(categories = ['M', 'F'], ordered = False)\n",
    "# Assign unordered categories to respective features\n",
    "# dataset['Sex'] = dataset['Sex'].astype(sex_cat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**STEP 5 - Split the dataset**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sklearn.model_selection as skl\n",
    "# First, split dataset into features and targets\n",
    "features = dataset.iloc[:, 0:6] # The first five columns are features\n",
    "target = dataset.iloc[:, 6:] # The last column is  the target\n",
    "print(features.head(5))\n",
    "print(target.head(5))\n",
    "# Assign training and testing data to respective arrays\n",
    "features_train, features_test, target_train, target_test = skl.train_test_split(features, target)\n",
    "# Save training and testing data to files\n",
    "features_train.to_csv(path_or_buf = 'features_train.csv')\n",
    "features_test.to_csv(path_or_buf = 'features_test.csv')\n",
    "target_train.to_csv(path_or_buf = 'target_train.csv')\n",
    "target_test.to_csv(path_or_buf = 'target_test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**STEP 6 - Run classifiers**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**STEP 6.a - NB**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Create the Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "# Train the model\n",
    "gnb.fit(features_train, target_train.values.ravel())\n",
    "target_prediction = gnb.predict(features_test)\n",
    "# Display the results\n",
    "print(\"a)\\n*****************************************************************************\\nGAUSSIAN NAIVE BAYES\\n\")\n",
    "print(\"b)\\nConfusion Matrix:\\n\", metrics.confusion_matrix(target_test, target_prediction))\n",
    "print(\"c)\\nPrecision:\\n\", metrics.confusion_matrix(target_test, target_prediction),\n",
    "      \"\\nRecall:\\n\", metrics.recall_score(target_test, target_prediction, average=None),\n",
    "      \"\\nF1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=None))\n",
    "print(\"d)\\nAccuracy:\\n\", metrics.accuracy_score(target_test, target_prediction),\n",
    "      \"\\nMacro-average F1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=\"macro\"),\n",
    "      \"\\nWeighted-average F1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=\"weighted\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**STEP 6.b - Base-DT**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Create the DT Classifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "# Train the model\n",
    "dtc.fit(features_train, target_train.values.ravel())\n",
    "target_prediction = dtc.predict(features_test)\n",
    "# Display the results\n",
    "print(\"a)\\n*****************************************************************************\\nBASE DECISION TREE\\n\")\n",
    "print(\"b)\\nConfusion Matrix:\\n\", metrics.confusion_matrix(target_test, target_prediction))\n",
    "print(\"c)\\nPrecision:\\n\", metrics.confusion_matrix(target_test, target_prediction),\n",
    "      \"\\nRecall:\\n\", metrics.recall_score(target_test, target_prediction, average=None),\n",
    "      \"\\nF1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=None))\n",
    "print(\"d)\\nAccuracy:\\n\", metrics.accuracy_score(target_test, target_prediction),\n",
    "      \"\\nMacro-average F1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=\"macro\"),\n",
    "      \"\\nWeighted-average F1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=\"weighted\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**STEP 6.c - Top-DT**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "# Establish hyper-parameters to be used in evaluation\n",
    "tree_parameters = {\n",
    "      'criterion':['entropy', 'gini'],\n",
    "      'max_depth':np.arange(3, 10),\n",
    "      'min_samples_split':[3, 4, 5]\n",
    "}\n",
    "# Create an instance of the GridSearchCV\n",
    "gscv = GridSearchCV(DecisionTreeClassifier(), tree_parameters)\n",
    "# Run the exhaustive grid search on hyper-parameters, given the test data\n",
    "gscv.fit(features_train, target_train.values.ravel())\n",
    "# Retrieve the best estimator (which uses the best parameters)\n",
    "print(gscv.best_estimator_)\n",
    "# Use the best estimator in the decision tree classifier\n",
    "target_prediction = gscv.best_estimator_.predict(features_test)\n",
    "# Display the results\n",
    "print(\"a)\\n*****************************************************************************\\nTOP DECISION TREE\\n\"\n",
    "      \"Best hyper-parameters:\", gscv.best_params_, \"\\n\")\n",
    "print(\"b)\\nConfusion Matrix:\\n\", metrics.confusion_matrix(target_test, target_prediction))\n",
    "print(\"c)\\nPrecision:\\n\", metrics.confusion_matrix(target_test, target_prediction),\n",
    "      \"\\nRecall:\\n\", metrics.recall_score(target_test, target_prediction, average=None),\n",
    "      \"\\nF1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=None))\n",
    "print(\"d)\\nAccuracy:\\n\", metrics.accuracy_score(target_test, target_prediction),\n",
    "      \"\\nMacro-average F1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=\"macro\"),\n",
    "      \"\\nWeighted-average F1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=\"weighted\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**STEP 6.d - PER**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "# Create the Perceptron classifier\n",
    "pc = Perceptron()\n",
    "# Train the model\n",
    "pc.fit(features_train, target_train.values.ravel())\n",
    "target_prediction = pc.predict(features_test)\n",
    "# Display the results\n",
    "print(\"a)\\n*****************************************************************************\\nPERCEPTRON\\n\")\n",
    "print(\"b)\\nConfusion Matrix:\\n\", metrics.confusion_matrix(target_test, target_prediction))\n",
    "print(\"c)\\nPrecision:\\n\", metrics.confusion_matrix(target_test, target_prediction),\n",
    "      \"\\nRecall:\\n\", metrics.recall_score(target_test, target_prediction, average=None),\n",
    "      \"\\nF1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=None))\n",
    "print(\"d)\\nAccuracy:\\n\", metrics.accuracy_score(target_test, target_prediction),\n",
    "      \"\\nMacro-average F1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=\"macro\"),\n",
    "      \"\\nWeighted-average F1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=\"weighted\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**STEP 6.e - Base-MLP**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# Create the MLP classifier with instructed parameters\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=100, activation=\"logistic\", solver=\"sgd\")\n",
    "# Train the model\n",
    "mlpc.fit(features_train, target_train.values.ravel())\n",
    "target_prediction = mlpc.predict(features_test)\n",
    "# Display the results\n",
    "print(\"a)\\n*****************************************************************************\\nBASE MULTI-LAYERED PERCEPTRON\\n\")\n",
    "print(\"b)\\nConfusion Matrix:\\n\", metrics.confusion_matrix(target_test, target_prediction))\n",
    "print(\"c)\\nPrecision:\\n\", metrics.confusion_matrix(target_test, target_prediction),\n",
    "      \"\\nRecall:\\n\", metrics.recall_score(target_test, target_prediction, average=None),\n",
    "      \"\\nF1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=None))\n",
    "print(\"d)\\nAccuracy:\\n\", metrics.accuracy_score(target_test, target_prediction),\n",
    "      \"\\nMacro-average F1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=\"macro\"),\n",
    "      \"\\nWeighted-average F1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=\"weighted\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**STEP 6.e - Top-MLP**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Establish hyper-parameters to be used in evaluation\n",
    "mlpc_parameters = {\n",
    "      'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    "      'hidden_layer_sizes':[(30, 50), (10, 10, 10)],\n",
    "      'solver':['adam', 'sgd']\n",
    "}\n",
    "# Create an instance of the GridSearchCV\n",
    "gscv = GridSearchCV(MLPClassifier(), mlpc_parameters)\n",
    "# Run the exhaustive grid search on hyper-parameters, given the test data\n",
    "gscv.fit(features_train, target_train.values.ravel())\n",
    "# Retrieve the best estimator (which uses the best parameters)\n",
    "print(gscv.best_estimator_)\n",
    "# Use the best estimator in the decision tree classifier\n",
    "target_prediction = gscv.best_estimator_.predict(features_test)\n",
    "# Display the results\n",
    "print(\"a)\\n*****************************************************************************\\nTOP MULTI-LAYERED PERCEPTRON\\n\"\n",
    "      \"Best hyper-parameters:\", gscv.best_params_, \"\\n\")\n",
    "print(\"b)\\nConfusion Matrix:\\n\", metrics.confusion_matrix(target_test, target_prediction))\n",
    "print(\"c)\\nPrecision:\\n\", metrics.confusion_matrix(target_test, target_prediction),\n",
    "      \"\\nRecall:\\n\", metrics.recall_score(target_test, target_prediction, average=None),\n",
    "      \"\\nF1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=None))\n",
    "print(\"d)\\nAccuracy:\\n\", metrics.accuracy_score(target_test, target_prediction),\n",
    "      \"\\nMacro-average F1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=\"macro\"),\n",
    "      \"\\nWeighted-average F1-measure:\\n\", metrics.f1_score(target_test, target_prediction, average=\"weighted\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}