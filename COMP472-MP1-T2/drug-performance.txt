** FILE CREATED: 2021-10-15 18:00:13.012527 **

a)
*****************************************************************************
GAUSSIAN NAIVE BAYES

b)
Confusion Matrix:
 [[ 5  0  0  0  0]
 [ 0  4  0  0  0]
 [ 0  0  5  0  0]
 [ 0  0  0 11  0]
 [ 1  1  1  0 22]]
c)
Precision:
 [[ 5  0  0  0  0]
 [ 0  4  0  0  0]
 [ 0  0  5  0  0]
 [ 0  0  0 11  0]
 [ 1  1  1  0 22]] 
Recall:
 [1.   1.   1.   1.   0.88] 
F1-measure:
 [0.90909091 0.88888889 0.90909091 1.         0.93617021]
d)
Accuracy:
 0.94 
Macro-average F1-measure:
 0.9286481839673328 
Weighted-average F1-measure:
 0.9410143993122716 

a)
*****************************************************************************
BASE DECISION TREE

b)
Confusion Matrix:
 [[ 5  0  0  0  0]
 [ 0  4  0  0  0]
 [ 0  0  5  0  0]
 [ 0  0  0 10  1]
 [ 0  0  0  0 25]]
c)
Precision:
 [[ 5  0  0  0  0]
 [ 0  4  0  0  0]
 [ 0  0  5  0  0]
 [ 0  0  0 10  1]
 [ 0  0  0  0 25]] 
Recall:
 [1.         1.         1.         0.90909091 1.        ] 
F1-measure:
 [1.         1.         1.         0.95238095 0.98039216]
d)
Accuracy:
 0.98 
Macro-average F1-measure:
 0.9865546218487395 
Weighted-average F1-measure:
 0.9797198879551821 

a)
*****************************************************************************
TOP DECISION TREE
Best hyper-parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 3} 

b)
Confusion Matrix:
 [[ 5  0  0  0  0]
 [ 0  4  0  0  0]
 [ 0  0  5  0  0]
 [ 0  0  0 10  1]
 [ 0  0  0  0 25]]
c)
Precision:
 [[ 5  0  0  0  0]
 [ 0  4  0  0  0]
 [ 0  0  5  0  0]
 [ 0  0  0 10  1]
 [ 0  0  0  0 25]] 
Recall:
 [1.         1.         1.         0.90909091 1.        ] 
F1-measure:
 [1.         1.         1.         0.95238095 0.98039216]
d)
Accuracy:
 0.98 
Macro-average F1-measure:
 0.9865546218487395 
Weighted-average F1-measure:
 0.9797198879551821 

a)
*****************************************************************************
PERCEPTRON

b)
Confusion Matrix:
 [[ 0  0  0  5  0]
 [ 0  0  0  4  0]
 [ 0  0  0  3  2]
 [ 0  0  0 10  1]
 [ 0  0  0 12 13]]
c)
Precision:
 [[ 0  0  0  5  0]
 [ 0  0  0  4  0]
 [ 0  0  0  3  2]
 [ 0  0  0 10  1]
 [ 0  0  0 12 13]] 
Recall:
 [0.         0.         0.         0.90909091 0.52      ] 
F1-measure:
 [0.         0.         0.         0.44444444 0.63414634]
d)
Accuracy:
 0.46 
Macro-average F1-measure:
 0.21571815718157183 
Weighted-average F1-measure:
 0.4148509485094851 

a)
*****************************************************************************
BASE MULTI-LAYERED PERCEPTRON

b)
Confusion Matrix:
 [[ 0  0  0  1  4]
 [ 0  0  0  4  0]
 [ 0  0  0  2  3]
 [ 0  0  0  7  4]
 [ 0  0  0  2 23]]
c)
Precision:
 [[ 0  0  0  1  4]
 [ 0  0  0  4  0]
 [ 0  0  0  2  3]
 [ 0  0  0  7  4]
 [ 0  0  0  2 23]] 
Recall:
 [0.         0.         0.         0.63636364 0.92      ] 
F1-measure:
 [0.         0.         0.         0.51851852 0.77966102]
d)
Accuracy:
 0.6 
Macro-average F1-measure:
 0.25963590709353424 
Weighted-average F1-measure:
 0.5039045825486503 

a)
*****************************************************************************
TOP MULTI-LAYERED PERCEPTRON
Best hyper-parameters: {'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'adam'} 

b)
Confusion Matrix:
 [[ 4  1  0  0  0]
 [ 1  3  0  0  0]
 [ 0  0  0  3  2]
 [ 0  0  0 10  1]
 [ 0  1  0  0 24]]
c)
Precision:
 [[ 4  1  0  0  0]
 [ 1  3  0  0  0]
 [ 0  0  0  3  2]
 [ 0  0  0 10  1]
 [ 0  1  0  0 24]] 
Recall:
 [0.8        0.75       0.         0.90909091 0.96      ] 
F1-measure:
 [0.8        0.66666667 0.         0.83333333 0.92307692]
d)
Accuracy:
 0.82 
Macro-average F1-measure:
 0.6446153846153846 
Weighted-average F1-measure:
 0.7782051282051282 


*****************************************************************************
STATISTICS


NB STATS:
Average accuracy: 0.94 
Average macro-average f1: 0.9286481839673328 
Average weighted-average f1: 0.9410143993122716 
Standard deviation accuracy: 1.1102230246251565e-16 
Standard deviation macro-average f1: 0.0 
Standard deviation weighted-average f1: 0.0 


BASE-DT STATS:
Average accuracy: 0.98 
Average macro-average f1: 0.9865546218487395 
Average weighted-average f1: 0.9797198879551821 
Standard deviation accuracy: 1.1102230246251565e-16 
Standard deviation macro-average f1: 0.0 
Standard deviation weighted-average f1: 0.0 


TOP-DT STATS:
Average accuracy: 0.98 
Average macro-average f1: 0.9865546218487395 
Average weighted-average f1: 0.9797198879551821 
Standard deviation accuracy: 1.1102230246251565e-16 
Standard deviation macro-average f1: 0.0 
Standard deviation weighted-average f1: 0.0 


PER STATS:
Average accuracy: 0.46 
Average macro-average f1: 0.21571815718157183 
Average weighted-average f1: 0.4148509485094851 
Standard deviation accuracy: 5.551115123125783e-17 
Standard deviation macro-average f1: 0.0 
Standard deviation weighted-average f1: 0.0 


BASE-MLP STATS:
Average accuracy: 0.608 
Average macro-average f1: 0.2649441058324752 
Average weighted-average f1: 0.5112491534700768 
Standard deviation accuracy: 0.009797958971132722 
Standard deviation macro-average f1: 0.006501189181845256 
Standard deviation weighted-average f1: 0.006501189181845256 


TOP-MLP STATS:
Average accuracy: 0.82 
Average macro-average f1: 0.6446153846153846 
Average weighted-average f1: 0.7782051282051282 
Standard deviation accuracy: 0.0 
Standard deviation macro-average f1: 0.0 
Standard deviation weighted-average f1: 0.0 

